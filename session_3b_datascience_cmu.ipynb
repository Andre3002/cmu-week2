{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Science - CMU Portugal Academy\n",
    "\n",
    "> \n",
    "> Instructors:\n",
    ">   - David Semedo (df.semedo@fct.unl.pt)\n",
    ">   - Rafael Ferreira (rah.ferreira@fct.unl.pt)\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Reference dataset - Mental Illness ([Link](https://www.kaggle.com/datasets/imtkaggleteam/mental-health))\n",
    "\n",
    "We will take the \"Mental Health\" dataset as reference, to introduce a set of Pandas operations.\n",
    "\n",
    "**Motivation**:\n",
    "\n",
    "* Mental health is an essential part of people’s lives and society. Poor mental health affects our well-being, our ability to work, and our relationships with friends, family, and community.\n",
    "\n",
    "* Mental health conditions are not uncommon. Hundreds of millions suffer from them yearly, and many more do over their lifetimes. It’s estimated that 1 in 3 women and 1 in 5 men will experience major depression in their lives. Other conditions, such as schizophrenia and bipolar disorder, are less common but still have a large impact on people’s lives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"datasets/1- mental-illnesses-prevalence.csv\"\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain an overview and basic informations about the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # Inspect the first 5. We can provide the size: df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single column Inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the operation above, is a Pandas Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"Year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns\n",
    "\n",
    "We can remove columns with the `DataFrame.drop()` function ([docs]([docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html))). There are multiple ways:\n",
    "* By specifying the axis index (0 for rows, 1 for columns): `df.drop(<column name string>, axis=1)`\n",
    "* By using the keyword argument `columns`: `df.drop(columns=<list of columns>)`\n",
    "\n",
    "\n",
    "Keep in mind that the drop operation, by default, is not an \"inplace\" operation, meaning that it returns a modified version of the original dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Num columns: {len(df.columns)}\")\n",
    "df.drop(columns=[\"Code\"])  # Equivalent to df.drop(\"Code\", axis=1)\n",
    "print(f\"Num columns after drop: {len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the inplace argument to True, or assign the returned DataFrame to the original variable:\n",
    "df.drop(columns=[\"Code\"], inplace=True)\n",
    "# or\n",
    "#df = df.drop(columns=[\"Code\"])\n",
    "print(f\"Num columns after drop: {len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative Variables: Obtain descriptive statistics from a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the maximum and minimum values of a given column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"].max(), df[\"Year\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Values\n",
    "\n",
    "For categorical values, we might want to know the domain size (i.e. how many unique values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_entities = df[\"Entity\"].unique() # Produces a NumPy array\n",
    "unique_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting operation, would be to know the distribution of the different values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Entity\"].value_counts().iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can index the resulting Series with the .iloc, and then use regular Python indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first 15 values\n",
    "df[\"Entity\"].value_counts().iloc[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test a condition over each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "anxiety_column = \"Anxiety disorders (share of population) - Sex: Both - Age: Age-standardized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[anxiety_column] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[anxiety_column] > 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This condition can be used to index the DataFrame, and obtain the rows for which the condition is True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[anxiety_column] > 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to do the same, but keep only a subset of the columns, we could used the .loc indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[anxiety_column] > 4, [\"Entity\", \"Year\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 1 - Descriptive statistics of the column Year\n",
    "\n",
    "Analyze the column the Year's distribution. What is its range, mean and std?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the distribution of the column Year. \n",
    "Comment on the dataset balance, based on the number of samples per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 2 - Compute the correlation between two columns\n",
    "\n",
    "Use the function `DataFrame.corr` to find the Pearson correlation between all pairs of following columns:\n",
    "\n",
    "* Schizophrenia disorders (share of population) - Sex: Both - Age: Age-standardized\n",
    "* Depressive disorders (share of population) - Sex: Both - Age: Age-standardized\n",
    "* Anxiety disorders (share of population) - Sex: Both - Age: Age-standardized\n",
    "* Bipolar disorders (share of population) - Sex: Both - Age: Age-standardized\n",
    "* Eating disorders (share of population) - Sex: Both - Age: Age-standardized\n",
    "\n",
    "Comment on the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Find the country with highest rate of Anxiety disorder\n",
    "\n",
    "Hint: The function .max() can be used to find the maximum value of a column. The function .argmax() gives you the index of that maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Remove outliers\n",
    "\n",
    "Removing outliers is a critical step when processing data.\n",
    "\n",
    "1. Pick one of the quantitative columns that represent a share of the population.\n",
    "2. Define an outlier as any value x, that is above two standard deviations.\n",
    "3. Remove all rows in which their corresponding values, exceed two standard deviations. \n",
    "4. Re-compute all the descriptive statistics over that column and compare the differences.\n",
    "\n",
    "Hint: In indexing, you can combine more than one condition (e.g. `df[(df[\"column\"] > a) & (df[\"column\"] < b)]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
